import { vi } from 'vitest';
import type { ILangfuseClient } from '../../shared/src/langfuse-client/langfuse-client.js';

export function createMockLangfuseClient(): ILangfuseClient {
  return {
    getTraces: vi.fn().mockResolvedValue({
      data: [
        {
          id: 'trace-1',
          timestamp: '2025-01-15T10:00:00Z',
          name: 'test-trace',
          sessionId: 'session-1',
          release: null,
          version: null,
          userId: 'user-1',
          tags: ['test'],
          public: false,
          environment: 'development',
          htmlPath: '/project/traces/trace-1',
          latency: 1.5,
          totalCost: 0.001,
          observations: ['obs-1', 'obs-2'],
          scores: ['score-1'],
        },
      ],
      meta: { page: 1, limit: 10, totalItems: 1, totalPages: 1 },
    }),

    getTraceDetail: vi.fn().mockResolvedValue({
      id: 'trace-1',
      timestamp: '2025-01-15T10:00:00Z',
      name: 'test-trace',
      input: { prompt: 'Hello world' },
      output: { response: 'Hi there!' },
      sessionId: 'session-1',
      release: null,
      version: null,
      userId: 'user-1',
      metadata: {},
      tags: ['test'],
      public: false,
      environment: 'development',
      htmlPath: '/project/traces/trace-1',
      latency: 1.5,
      totalCost: 0.001,
      observations: [
        {
          id: 'obs-1',
          traceId: 'trace-1',
          type: 'GENERATION',
          name: 'chat-completion',
          startTime: '2025-01-15T10:00:00Z',
          endTime: '2025-01-15T10:00:01Z',
          model: 'gpt-4',
          level: 'DEFAULT',
          statusMessage: null,
          parentObservationId: null,
          version: null,
          latency: 1.0,
          usageDetails: { input: 100, output: 50 },
          costDetails: { input: 0.0003, output: 0.0006 },
        },
      ],
      scores: [
        {
          id: 'score-1',
          traceId: 'trace-1',
          name: 'accuracy',
          source: 'API',
          dataType: 'NUMERIC',
          value: 0.95,
          timestamp: '2025-01-15T10:00:02Z',
          createdAt: '2025-01-15T10:00:02Z',
          updatedAt: '2025-01-15T10:00:02Z',
        },
      ],
    }),

    getObservations: vi.fn().mockResolvedValue({
      data: [
        {
          id: 'obs-1',
          traceId: 'trace-1',
          type: 'GENERATION',
          name: 'chat-completion',
          startTime: '2025-01-15T10:00:00Z',
          endTime: '2025-01-15T10:00:01Z',
          model: 'gpt-4',
          level: 'DEFAULT',
          statusMessage: null,
          parentObservationId: null,
          version: null,
          latency: 1.0,
          usageDetails: { input: 100, output: 50 },
          costDetails: { input: 0.0003, output: 0.0006 },
        },
      ],
      meta: { page: 1, limit: 10, totalItems: 1, totalPages: 1 },
    }),

    getObservation: vi.fn().mockResolvedValue({
      id: 'obs-1',
      traceId: 'trace-1',
      type: 'GENERATION',
      name: 'chat-completion',
      startTime: '2025-01-15T10:00:00Z',
      endTime: '2025-01-15T10:00:01Z',
      model: 'gpt-4',
      input: { messages: [{ role: 'user', content: 'Hello' }] },
      output: { choices: [{ message: { content: 'Hi!' } }] },
      metadata: {},
      modelParameters: { temperature: 0.7 },
      level: 'DEFAULT',
      statusMessage: null,
      parentObservationId: null,
      version: null,
      latency: 1.0,
      usageDetails: { input: 100, output: 50 },
      costDetails: { input: 0.0003, output: 0.0006 },
    }),
  };
}
